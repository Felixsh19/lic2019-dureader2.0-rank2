global:
  random_seed: 123
  gpu: 0                # GPU id for training and testing
  num_data_workers: 5   # for data loader
  model: match-lstm+    # 'match-lstm', 'match-lstm+', 'r-net', 'm-reader' or 'base'
                        # Note that 'base' model is customized by base_model.yaml

data:
  data_type: search
  mrc_dataset:
    train_path: input/dureader_2.0/mrc_dataset/trainset/search.train.json
    dev_path: input/dureader_2.0/mrc_dataset/devset/search.dev.json
    test_path: input/dureader_2.0/mrc_dataset/testset/search.test1.json

  data_cache_dir: input/dureader_2.0/mrc_data_cache

  train_badcase_save_file: logs/search/train_badcase.json
  embeddings_file: ../../pretrained_embeddings/chinese/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5
  max_p_num: 5
  max_p_len: 500
  max_q_len: 60
  min_word_cnt: 2
